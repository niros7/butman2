{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "# change the path to your train pictures file\n",
    "train_path = './Train/';\n",
    "\n",
    "X = []\n",
    "for filename in os.listdir(train_path):\n",
    "    X.append(img_to_array(load_img(train_path + filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "# Set up train and test data\n",
    "split = int(0.90*len(X))\n",
    "print(split)\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(96, 96, 1)))\n",
    "model.add(Conv2D(24, (3, 3), activation='relu', padding='same'))              \n",
    "model.add(Conv2D(24, (3, 3), activation='relu', padding='same', strides=2))   \n",
    "model.add(Conv2D(48, (3, 3), activation='relu', padding='same'))              \n",
    "model.add(Conv2D(48, (3, 3), activation='relu', padding='same', strides=2))   \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same', strides=2))   \n",
    "model.add(Conv2D(192, (3, 3), activation='sigmoid', padding='same'))             \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(24, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(12, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))               \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n"
     ]
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 15\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "print(batch_size * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "144/144 [==============================] - 102s 711ms/step - loss: 0.0449\n",
      "Epoch 2/15\n",
      "144/144 [==============================] - 104s 722ms/step - loss: 0.0343\n",
      "Epoch 3/15\n",
      "144/144 [==============================] - 103s 716ms/step - loss: 0.0332\n",
      "Epoch 4/15\n",
      "144/144 [==============================] - 101s 703ms/step - loss: 0.0325\n",
      "Epoch 5/15\n",
      "144/144 [==============================] - 101s 703ms/step - loss: 0.0323\n",
      "Epoch 6/15\n",
      "144/144 [==============================] - 101s 703ms/step - loss: 0.0324\n",
      "Epoch 7/15\n",
      "144/144 [==============================] - 101s 699ms/step - loss: 0.0325\n",
      "Epoch 8/15\n",
      "144/144 [==============================] - 101s 699ms/step - loss: 0.0323\n",
      "Epoch 9/15\n",
      "144/144 [==============================] - 101s 700ms/step - loss: 0.0321\n",
      "Epoch 10/15\n",
      "144/144 [==============================] - 100s 696ms/step - loss: 0.0323\n",
      "Epoch 11/15\n",
      "144/144 [==============================] - 102s 707ms/step - loss: 0.0322\n",
      "Epoch 12/15\n",
      "144/144 [==============================] - 101s 698ms/step - loss: 0.0322\n",
      "Epoch 13/15\n",
      "144/144 [==============================] - 101s 699ms/step - loss: 0.0325\n",
      "Epoch 14/15\n",
      "144/144 [==============================] - 101s 700ms/step - loss: 0.0322\n",
      "Epoch 15/15\n",
      "144/144 [==============================] - 101s 702ms/step - loss: 0.0324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f7f22a4e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steps per epoc - whole dataset / batch_size\n",
    "model.fit_generator(image_a_b_gen(batch_size), epochs=15, steps_per_epoch= split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 18ms/step\n",
      "0.0152834173641\n"
     ]
    }
   ],
   "source": [
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "color_me = []\n",
    "test_path = './Test/'\n",
    "for filename in os.listdir(test_path):\n",
    "    color_me.append(img_to_array(load_img(test_path+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((96, 96, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}