{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to your train pictures file\n",
    "train_path = './Train/';\n",
    "\n",
    "X = []\n",
    "for filename in os.listdir(train_path):\n",
    "    X.append(img_to_array(load_img(train_path + filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "# Set up train and validation data\n",
    "split = int(0.90*len(X))\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*Xtrain\n",
    "\n",
    "Xval = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xval = Xval.reshape(Xval.shape+(1,))\n",
    "Yval = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Yval = Yval / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(96, 96, 1)))\n",
    "model.add(Conv2D(24, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(24, (3, 3), activation='sigmoid', padding='same', strides=2))   \n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid', padding='same', strides=2))   \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same', strides=2))   \n",
    "model.add(Conv2D(192, (3, 3), activation='sigmoid', padding='same'))             \n",
    "model.add(Conv2D(96, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(24, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(12, (3, 3), activation='sigmoid', padding='same'))              \n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))               \n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 5\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "print(batch_size * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "36/36 [==============================] - 10s 284ms/step - loss: 0.0933 - val_loss: 0.0239\n",
      "Epoch 2/15\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 0.0283 - val_loss: 0.0191\n",
      "Epoch 3/15\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 0.0245 - val_loss: 0.0186\n",
      "Epoch 4/15\n",
      "36/36 [==============================] - 9s 242ms/step - loss: 0.0256 - val_loss: 0.0183\n",
      "Epoch 5/15\n",
      "36/36 [==============================] - 8s 232ms/step - loss: 0.0248 - val_loss: 0.0179\n",
      "Epoch 6/15\n",
      "36/36 [==============================] - 8s 228ms/step - loss: 0.0243 - val_loss: 0.0180\n",
      "Epoch 7/15\n",
      "36/36 [==============================] - 8s 231ms/step - loss: 0.0243 - val_loss: 0.0181\n",
      "Epoch 8/15\n",
      "36/36 [==============================] - 8s 228ms/step - loss: 0.0239 - val_loss: 0.0173\n",
      "Epoch 9/15\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 0.0238 - val_loss: 0.0172\n",
      "Epoch 10/15\n",
      "36/36 [==============================] - 9s 241ms/step - loss: 0.0237 - val_loss: 0.0173\n",
      "Epoch 11/15\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 0.0233 - val_loss: 0.0173\n",
      "Epoch 12/15\n",
      "36/36 [==============================] - 8s 229ms/step - loss: 0.0231 - val_loss: 0.0177\n",
      "Epoch 13/15\n",
      "36/36 [==============================] - 9s 238ms/step - loss: 0.0253 - val_loss: 0.0202\n",
      "Epoch 14/15\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 0.0232 - val_loss: 0.0169\n",
      "Epoch 15/15\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 0.0232 - val_loss: 0.0167\n"
     ]
    }
   ],
   "source": [
    "# steps per epoc - whole dataset / batch_size\n",
    "model.fit_generator(image_a_b_gen(batch_size), epochs=15, steps_per_epoch= split, validation_data=(Xtest, Ytest))\n",
    "model.save('colorizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "c:\\users\\tsofan\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "color_me = []\n",
    "test_path = './Test/'\n",
    "for filename in os.listdir(test_path):\n",
    "    color_me.append(img_to_array(load_img(test_path+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((96, 96, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
